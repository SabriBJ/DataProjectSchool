{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rahk51WkMsQV"
   },
   "source": [
    "# HMIN232M - Automatic fact-checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dl5D9kX5WyXD"
   },
   "source": [
    "```\n",
    "Sabri BENBRAHIM - 21604014\n",
    "Bénédicte DAYNAC - 21605192\n",
    "Yann DUFRESNE - 20055179\n",
    "Llivia LANGEVIN - 21604582\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28nQGnF9MsQX"
   },
   "source": [
    "### Imports globaux préalables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "Y9J_Yh9cMsQZ",
    "outputId": "18f0ac36-ea08-44a0-c9c0-7070a2732df1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "\n",
    "# pour colab\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# pour colab\n",
    "!pip install contractions\n",
    "\n",
    "import contractions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy\n",
    "import unicodedata\n",
    "from time import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "#python version 2 or 3\n",
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    print(\"python2\")\n",
    "else:\n",
    "    print(\"python3\")\n",
    "    \n",
    "#python architecture 32 or 64 bits\n",
    "import platform\n",
    "print(platform.architecture()[0])\n",
    "\n",
    "#run garbage collector\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "#free memory size\n",
    "import psutil\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBiMUzZLMsQm"
   },
   "source": [
    "### Fonctions elémentaires récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lMaF9SGrMsQn",
    "outputId": "c1f3a716-fc9a-4c95-ddef-c6475b18c6a2"
   },
   "outputs": [],
   "source": [
    "#remove html (clean)\n",
    "from bs4 import BeautifulSoup\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "# replave contractions (clean)\n",
    "import contractions\n",
    "def replace_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# replace numbers to words (token)\n",
    "import inflect\n",
    "def numbers_to_words(tokens):\n",
    "    result=[]\n",
    "    p = inflect.engine()\n",
    "    for t in tokens:\n",
    "        if t.isdigit():\n",
    "            t = p.number_to_words(t)\n",
    "        result.append(t)\n",
    "    return result\n",
    "\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Czphlw0zMsQr"
   },
   "source": [
    "## Importation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "9Iuhq07-MsQs",
    "outputId": "f581f286-5032-42ea-9d8e-14d546c6660b"
   },
   "outputs": [],
   "source": [
    "dataFile=\"data-truefalse.csv\" # data-truefalse-1.csv data-truefalse-2.csv data-truefalse-3.csv data-truefalse.csv data-mixture.csv\n",
    "\n",
    "XColumnName= \"claimReview_claimReviewed\"\n",
    "yColumnName= \"true_false_mixture\"\n",
    "\n",
    "print(\"Chargement CSV: \",dataFile)\n",
    "dfOrigin=pd.read_csv(dataFile, sep='\\t')\n",
    "\n",
    "# ! necessaire pour mixture, a mettre en commentaire pour truefalse !\n",
    "#dfOrigin.loc[dfOrigin[yColumnName] == -1, yColumnName] = 1\n",
    "\n",
    "display(dfOrigin.head())\n",
    "print(\"dfOrigin taille:\",dfOrigin.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzIlPGpDMsQy"
   },
   "source": [
    "## Nettoyage et prétraitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnTxvDcgMsQy"
   },
   "source": [
    "### sur les claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uN7sH2huMsQz"
   },
   "source": [
    "#### suppression caractères non utf8, html, formes anglaise contractées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8_3F6AvMsQ0"
   },
   "outputs": [],
   "source": [
    "def preclean_data(df):\n",
    "    \n",
    "    # print(\"preclean claims\")\n",
    "\n",
    "    # clean encodage\n",
    "    index = df.index.values\n",
    "    for i in index:\n",
    "        if not pd.isnull(df.at[i]):\n",
    "            df.at[i]=unicodedata.normalize('NFKD', df.at[i]).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "            # c=unicodedata.normalize('NFKD', unicode(str(df.at[i])).encode('ascii','ignore') #python2\n",
    "\n",
    "    # remove html\n",
    "    for i in index:\n",
    "        if not pd.isnull(df.at[i]):\n",
    "            df.at[i]=strip_html(df.at[i])\n",
    "    \n",
    "    # replace contractions\n",
    "    for i in index:\n",
    "        if not pd.isnull(df.at[i]):\n",
    "            df.at[i]=replace_contractions(df.at[i])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "xMi0iWMgMsQ4",
    "outputId": "9d306fa3-34df-4584-93a8-4b7852ad743e"
   },
   "outputs": [],
   "source": [
    "claimsClean=dfOrigin[XColumnName].copy()\n",
    "\n",
    "print(\"Avant:\")\n",
    "print(claimsClean.head(),'\\n')\n",
    "\n",
    "claimsClean = preclean_data(claimsClean)\n",
    "\n",
    "print(\"Apres Clean:\")\n",
    "print(claimsClean.head(),'\\n')\n",
    "print(\"claimsClean taille:\",claimsClean.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QmtdzrBMsQ9"
   },
   "source": [
    "### sur les tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Dz7EY7_MsQ-"
   },
   "source": [
    "#### passage en  minuscule, convertion des chiffres en lettres, suppression des caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwFUX-FuMsQ_"
   },
   "outputs": [],
   "source": [
    "def token_data(df):\n",
    "    \n",
    "    # print(\"clean tokens\")\n",
    "\n",
    "    df = df.astype('object')\n",
    "    index = df.index.values\n",
    "    for i in index:\n",
    "        tokensClaimsResult=[]\n",
    "        if not pd.isnull(df.at[i]):\n",
    "            phrases = sent_tokenize(df.at[i])\n",
    "            for p in phrases:\n",
    "                tokens = word_tokenize(p)\n",
    "                # minuscule\n",
    "                tokens = [t.lower() for t in tokens]\n",
    "                # replace number to letters\n",
    "                tokens = numbers_to_words(tokens)\n",
    "                # remove non-alpha signs\n",
    "                tokens = [t for t in tokens if t.isalpha()]\n",
    "                for t in tokens:\n",
    "                    tokensClaimsResult.append(t) \n",
    "            df.at[i]=tokensClaimsResult\n",
    "        else:\n",
    "            df.at[i]=[]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "qT6o0j8AMsRG",
    "outputId": "dfb27a23-b5c2-4d5f-f777-162051515101"
   },
   "outputs": [],
   "source": [
    "claimsTokens=claimsClean.copy()\n",
    "\n",
    "print(\"Avant:\")\n",
    "print(claimsTokens.head(),'\\n')\n",
    "\n",
    "claimsTokens = token_data(claimsTokens)\n",
    "\n",
    "print(\"Apres Token:\")\n",
    "print(claimsTokens.head(),'\\n')\n",
    "print(\"claimsTokens taille:\",claimsTokens.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jebfAEVIMsRL"
   },
   "source": [
    "## Merge des tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXE3dh0cMsRM"
   },
   "outputs": [],
   "source": [
    "def merge_tokens(df):\n",
    "    \n",
    "    # print(\"merge tokens\")\n",
    "\n",
    "    claimsToStr=[]\n",
    "    index = df.index.values\n",
    "    for i in index:\n",
    "        line=\"\"\n",
    "        if df.at[i] != []:\n",
    "            for w in df.at[i]:\n",
    "                line+=\" \"+w\n",
    "        df.at[i]=line.strip()    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "qcJSoKZ_MsRP",
    "outputId": "162c5a3d-f87f-4b36-df6d-c921e2be9d0b"
   },
   "outputs": [],
   "source": [
    "claimsMergeInit=claimsTokens.copy()\n",
    "\n",
    "print(\"Avant:\")\n",
    "print(claimsMergeInit.head(),'\\n')\n",
    "\n",
    "claimsMergeInit = merge_tokens(claimsMergeInit)\n",
    "\n",
    "print(\"Apres Merge:\")\n",
    "print(claimsMergeInit.head(),'\\n')\n",
    "print(\"claimsMerge taille:\",claimsMergeInit.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QFTJQotMsRT"
   },
   "source": [
    "## Resultat sur un premier classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSow-gmoMsRV"
   },
   "outputs": [],
   "source": [
    "def do_classifier(dfComplet, column, dfEval, trace):\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # Vectorisation\n",
    "    vectorizerT = TfidfVectorizer(min_df=2)\n",
    "    vectorT = vectorizerT.fit_transform(dfEval)\n",
    "\n",
    "    gc.collect()\n",
    "    if trace:\n",
    "        print(\"Vocabulary:\")\n",
    "        i=0\n",
    "        limit=50\n",
    "        for key, value in vectorizerT.vocabulary_.items():\n",
    "            print (key, end=', ')\n",
    "            i+=1\n",
    "            if i>= limit:\n",
    "                break\n",
    "        print(\"\\nTfidVector taille: \",vectorT.shape)\n",
    "        print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "\n",
    "    # Jeux d'apprentissage\n",
    "    X=vectorT.toarray()\n",
    "    y=dfComplet[column].copy()\n",
    "    gc.collect()\n",
    "    if trace:\n",
    "        print (\"X taille: \",X.shape)\n",
    "        print (\"y taille: \",y.shape)\n",
    "        print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "\n",
    "    validation_size=0.25\n",
    "    testsize= 1-validation_size\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   train_size=validation_size, \n",
    "                                                   random_state=20,\n",
    "                                                   test_size=testsize)\n",
    "    gc.collect()\n",
    "    if trace:\n",
    "        print (\"X_train taille: \",X_train.shape)\n",
    "        print (\"X_test taille: \",X_test.shape)\n",
    "        print (\"y_train taille: \",y_train.shape)\n",
    "        print (\"y_test taille: \",y_test.shape)\n",
    "        print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "\n",
    "    # Classifieurs par defaut\n",
    "    \n",
    "    # GaussianNB\n",
    "    #clfN=\"GaussianNB\"\n",
    "    #print(clfN)\n",
    "    #clf = GaussianNB()\n",
    "    \n",
    "    # LinearSVC\n",
    "    clfN=\"LinearSVC\"\n",
    "    print(clfN)\n",
    "    #clf = LinearSVC()\n",
    "    clf = CalibratedClassifierCV(LinearSVC()) \n",
    "\n",
    "    # Execution et resultats\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision,recall,fscore,support=score(y_test,y_pred,average='macro')\n",
    "\n",
    "    print(\"Accuracy: %.3f%%\" % (accuracy * 100.0))\n",
    "    print(\"F1-score moyen: %.3f%%\\n\" % (fscore * 100.0))\n",
    "    print ('Matrice de confusion:\\n', confusion_matrix(y_test, y_pred),'\\n')\n",
    "    print (classification_report(y_test, y_pred))\n",
    "\n",
    "    # Roc Curve\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = clf.predict_proba(X_test)\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "    print('Sans modèle : ROC AUC =%.3f' % (ns_auc))\n",
    "    print('Avec',clfN,' : ROC AUC =%.3f' % (lr_auc))\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Pas de Modele')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label=clfN)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Réalisé en %.1fs\" % (time() - t0))\n",
    "    \n",
    "    del vectorT, X, y, X_train, X_test, y_train, y_test\n",
    "    #del ns_probs, lr_probs, ns_auc, lr_auc, ns_fpr, ns_tpr, lr_fpr, lr_tpr\n",
    "    print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "    \n",
    "    return fscore    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "TZJc6r2qMsRc",
    "outputId": "3babcd79-d9ec-40bd-c7f9-ed778eb9491a"
   },
   "outputs": [],
   "source": [
    "# Première valeur de score de référence\n",
    "scoreInit = do_classifier(dfOrigin, yColumnName, claimsMergeInit, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-0S9BYBMsRg"
   },
   "source": [
    "## Etude sur la suppression des Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxg1W9T_MsRh"
   },
   "outputs": [],
   "source": [
    "def stop_data(df, trace):\n",
    "    \n",
    "    if trace:\n",
    "        print(\"remove stopwords\")\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # stop_words = set(stopwords.words('french')) #fr?\n",
    "    index = df.index.values\n",
    "    for i in index:\n",
    "        if df.at[i] != []:\n",
    "            withoutStopWordsClaims=[]\n",
    "            withoutStopWordsClaims = [w for w in df.at[i] if not w in stop_words]\n",
    "            df.at[i]=withoutStopWordsClaims\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "ABmkWcMKMsRm",
    "outputId": "467666c4-d3b1-4d5f-856b-1c4c8b3e297a"
   },
   "outputs": [],
   "source": [
    "claimsStop=claimsTokens.copy()\n",
    "\n",
    "print(\"Avant:\")\n",
    "print(claimsStop.head(),'\\n')\n",
    "\n",
    "claimsStop = stop_data(claimsStop, True)\n",
    "\n",
    "print(\"Apres Stop:\")\n",
    "print(claimsStop.head(),'\\n')\n",
    "print(\"claimsStop taille:\",claimsStop.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "zn6ztX8kMsRq",
    "outputId": "d390d362-28eb-4bf1-a9ea-58ea95b31415"
   },
   "outputs": [],
   "source": [
    "StopWords= False # False True\n",
    "\n",
    "claimsMergeStop = merge_tokens(claimsStop.copy())\n",
    "scoreStop = do_classifier(dfOrigin, yColumnName,claimsMergeStop, False)\n",
    "\n",
    "# Memorisation des parametres en fonction de l'évolution du score\n",
    "if scoreStop >= scoreInit:\n",
    "    StopWords= True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWoIicu3MsRx"
   },
   "source": [
    "## Etude sur la Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2WJ0FnBMsRy"
   },
   "outputs": [],
   "source": [
    "def lemm_data(df, trace):\n",
    "    \n",
    "    if trace:\n",
    "        print(\"lemmatize tokens\")\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    index = df.index.values\n",
    "    for i in index:\n",
    "        if df.at[i] != []:\n",
    "            df.at[i]=[lemmatizer.lemmatize(word,pos='v') for word in df.at[i]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "dtRC3NMRMsR5",
    "outputId": "7b9bf853-7caa-48fd-e931-5bde898a438b"
   },
   "outputs": [],
   "source": [
    "claimsLem=claimsTokens.copy()\n",
    "\n",
    "print(\"Avant:\")\n",
    "print(claimsLem.head(),'\\n')\n",
    "\n",
    "claimsLem = lemm_data(claimsLem, True)\n",
    "\n",
    "print(\"Apres Lemm:\")\n",
    "print(claimsLem.head(),'\\n')\n",
    "print(\"claimsLem taille:\",claimsLem.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "d9RSqyoVMsR-",
    "outputId": "1cf4d57a-a639-4625-8598-5bb55a20179e"
   },
   "outputs": [],
   "source": [
    "Lemmatiz= False # False True\n",
    "\n",
    "claimsMergeLem = merge_tokens(claimsLem.copy())\n",
    "scoreLem = do_classifier(dfOrigin, yColumnName, claimsMergeLem, False)\n",
    "\n",
    "# Memorisation des parametres en fonction de l'évolution du score\n",
    "if StopWords:\n",
    "    if scoreLem >= scoreStop:\n",
    "        Lemmatiz= True\n",
    "else:\n",
    "    if scoreLem >= scoreInit:\n",
    "        Lemmatiz= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GV3UKY9nMsSC"
   },
   "outputs": [],
   "source": [
    "# Nettoyage complet paramétrable sans merge\n",
    "def fullclean_data(column, stop, lemm, trace):\n",
    "\n",
    "    result = preclean_data(column)\n",
    "    result = token_data(result)\n",
    "    if stop:\n",
    "        result = stop_data(result, trace)\n",
    "    if lemm:\n",
    "        result = lemm_data(result, trace)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iy2Q0DyHMsSN"
   },
   "source": [
    "## Etude sur l'ajout d'extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_uAJJsHMsSO"
   },
   "source": [
    "### Creation des jeux de données avec ajouts de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzCaI03qMsSP"
   },
   "outputs": [],
   "source": [
    "def addtokens_2in1(df1,df2):\n",
    "    \n",
    "    index = df1.index.values\n",
    "    for i in index:\n",
    "        line=[]\n",
    "        if df1.at[i] != []:\n",
    "            for w in df1.at[i]:\n",
    "                line.append(w)\n",
    "        if df2.at[i] != []:\n",
    "            for w in df2.at[i]:\n",
    "                line.append(w)\n",
    "        df1.at[i]=line  \n",
    "        \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCD8mkZ0MsSU"
   },
   "outputs": [],
   "source": [
    "def addExtras(df, column, extraType, stop, lemm):\n",
    "\n",
    "    if extraType == \"addauthor\" or extraType == \"addall\":\n",
    "        print(\"Wait...\")\n",
    "        print(\"Clean author extras\")\n",
    "        extra1=df['creativeWork_author_name'].copy()\n",
    "        extra2=df['extra_author_categories'].copy()\n",
    "        extra1 = fullclean_data(extra1, stop, lemm, False)\n",
    "        extra2 = fullclean_data(extra2, stop, lemm, False)\n",
    "\n",
    "    if extraType == \"addall\":\n",
    "        print(\"Clean other extras\")\n",
    "        extra3=df['extra_claimReview_claimReviewed_entity'].copy()\n",
    "        extra4=df['extra_claimReview_claimReviewed_categories'].copy()\n",
    "        extra5=df['extra_keywords_entity'].copy()\n",
    "        extra6=df['extra_keywords_categories'].copy()\n",
    "        extra7=df['extra_tags'].copy()\n",
    "        #extra8=df['extra_title'].copy()\n",
    "        extra3 = fullclean_data(extra3, stop, lemm, False)\n",
    "        extra4 = fullclean_data(extra4, stop, lemm, False)\n",
    "        extra5 = fullclean_data(extra5, stop, lemm, False)\n",
    "        extra6 = fullclean_data(extra6, stop, lemm, False)\n",
    "        extra7 = fullclean_data(extra7, stop, lemm, False)\n",
    "        #extra8 = fullclean_data(extra8, stop, lemm, False)\n",
    "\n",
    "    if extraType == \"addauthor\" or extraType == \"addall\":\n",
    "        print(\"Extras cleaned\")\n",
    "        \n",
    "    dfResult = df[column].copy()\n",
    "    dfResult = fullclean_data(dfResult, stop, lemm, True)\n",
    "        \n",
    "    if extraType == \"addauthor\" or extraType == \"addall\":\n",
    "        print(\"Add author extras\")\n",
    "        dfResult=addtokens_2in1(dfResult,extra1)\n",
    "        dfResult=addtokens_2in1(dfResult,extra2)\n",
    "        del extra1, extra2\n",
    "\n",
    "    if extraType == \"addall\":\n",
    "        print(\"Add other extras\")\n",
    "        dfResult=addtokens_2in1(dfResult,extra3)\n",
    "        dfResult=addtokens_2in1(dfResult,extra4)\n",
    "        dfResult=addtokens_2in1(dfResult,extra5)\n",
    "        dfResult=addtokens_2in1(dfResult,extra6)\n",
    "        dfResult=addtokens_2in1(dfResult,extra7)\n",
    "        #dfResult=addtokens_2in1(dfResult,extra8)\n",
    "        del extra3, extra4, extra5, extra6, extra7 #, extra8\n",
    "\n",
    "    if extraType == \"addauthor\" or extraType == \"addall\":\n",
    "        print(\"Extras added\")\n",
    "        \n",
    "    print(extraType,\"done\")\n",
    "    \n",
    "    return dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "RKT-UYTbMsSY",
    "outputId": "6fb5fcb2-0ef3-44e7-a951-22d5110daa96"
   },
   "outputs": [],
   "source": [
    "includeExtra=\"addnone\" # addnone addauthor addall\n",
    "\n",
    "dfAjout1 = addExtras(dfOrigin, XColumnName, \"addnone\", StopWords, Lemmatiz)\n",
    "print(dfAjout1.head())\n",
    "print(\"dfAjout1 taille:\",dfAjout1.shape,'\\n')\n",
    "\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "\n",
    "dfAjout2 = addExtras(dfOrigin, XColumnName, \"addauthor\", StopWords, Lemmatiz)\n",
    "print(dfAjout2.head())\n",
    "print(\"dfAjout2 taille:\",dfAjout2.shape,'\\n')\n",
    "\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "\n",
    "dfAjout3 = addExtras(dfOrigin, XColumnName, \"addall\", StopWords, Lemmatiz)\n",
    "print(dfAjout3.head())\n",
    "print(\"dfAjout3 taille:\",dfAjout3.shape,'\\n')\n",
    "\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKjGhE8MMsSf"
   },
   "source": [
    "### Evaluation des changements suite aux ajouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XErtUoyAMsSg",
    "outputId": "bc3f9fbc-d660-40b3-d617-be02b7f4b3b8"
   },
   "outputs": [],
   "source": [
    "claimsMergeAjout1 = merge_tokens(dfAjout1.copy())\n",
    "print(\"addnone\")\n",
    "scoreAjout1 = do_classifier(dfOrigin, yColumnName, claimsMergeAjout1, False)\n",
    "\n",
    "claimsMergeAjout2 = merge_tokens(dfAjout2.copy())\n",
    "print(\"addauthor\")\n",
    "scoreAjout2 = do_classifier(dfOrigin, yColumnName, claimsMergeAjout2, False)\n",
    "\n",
    "claimsMergeAjout3 = merge_tokens(dfAjout3.copy())\n",
    "print(\"addall\")\n",
    "scoreAjout3 = do_classifier(dfOrigin, yColumnName, claimsMergeAjout3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuvxvGjmMsSk"
   },
   "outputs": [],
   "source": [
    "def NextDf(dfO):\n",
    "\n",
    "    dfN = dfO.copy()\n",
    "    \n",
    "    dfN = dfN.drop('creativeWork_author_name', 1)\n",
    "    dfN = dfN.drop('extra_author_categories', 1)\n",
    "    dfN = dfN.drop('extra_claimReview_claimReviewed_entity', 1)\n",
    "    dfN = dfN.drop('extra_claimReview_claimReviewed_categories', 1)\n",
    "    dfN = dfN.drop('extra_keywords_entity', 1)\n",
    "    dfN = dfN.drop('extra_keywords_categories', 1)\n",
    "    dfN = dfN.drop('extra_tags', 1)\n",
    "    dfN = dfN.drop('extra_title', 1)\n",
    "\n",
    "    return dfN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "6iHrjwxtMsSn",
    "outputId": "dc96d139-6248-4271-c5a6-2f8b44daf259"
   },
   "outputs": [],
   "source": [
    "# Memorisation des parametres en fonction de l'évolution du score\n",
    "if scoreAjout2>scoreAjout1:\n",
    "    includeExtra = \"addauthor\"\n",
    "\n",
    "if includeExtra == \"addauthor\":\n",
    "    if scoreAjout3>scoreAjout2:\n",
    "        includeExtra = \"addall\"\n",
    "else:\n",
    "    if scoreAjout3>scoreAjout1:\n",
    "        includeExtra = \"addall\"\n",
    "\n",
    "# Nouveau dataframe de travail\n",
    "dfNext = NextDf(dfOrigin)\n",
    "        \n",
    "if includeExtra == \"addnone\":\n",
    "    finalColumn = pd.DataFrame(claimsMergeAjout1)\n",
    "    finalColumn.columns = [XColumnName]\n",
    "    dfNext.update(finalColumn)\n",
    "\n",
    "if includeExtra == \"addauthor\":\n",
    "    finalColumn = pd.DataFrame(claimsMergeAjout2)\n",
    "    finalColumn.columns = [XColumnName]\n",
    "    dfNext.update(finalColumn)\n",
    "\n",
    "if includeExtra == \"addall\":\n",
    "    finalColumn = pd.DataFrame(claimsMergeAjout3)\n",
    "    finalColumn.columns = [XColumnName]\n",
    "    dfNext.update(finalColumn)\n",
    "    \n",
    "del dfOrigin, dfAjout1, dfAjout2, dfAjout3, claimsMergeAjout1, claimsMergeAjout2, claimsMergeAjout3\n",
    "\n",
    "print(\"Apres Add:\")\n",
    "display(dfNext.head())\n",
    "print(\"dfNext taille:\",dfNext.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GNnrncQUMsSr"
   },
   "source": [
    "## Etude sur le rééquilibrage du rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "7K9IhmhjMsSr",
    "outputId": "343d5f9d-e1bb-47e2-cea1-37cd4f24d4bd"
   },
   "outputs": [],
   "source": [
    "print(\"Avant resampling:\")\n",
    "print(dfNext[yColumnName].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Qs4edTcMsSv"
   },
   "source": [
    "### Creation des jeux de données resamplés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzoID31jMsSw"
   },
   "outputs": [],
   "source": [
    "def resampleDf(df, column, method):\n",
    "    \n",
    "    if method == \"noresampling\":\n",
    "        dfResult = df.copy()\n",
    "\n",
    "    else:\n",
    "        count_big, count_small = df[column].value_counts()\n",
    "        ordered_val = df[column].value_counts().index.tolist()\n",
    "\n",
    "        dfBig = df[df[column] == ordered_val[0]]\n",
    "        dfSmall = df[df[column] == ordered_val[1]]\n",
    "\n",
    "        if method == \"downsampling\": # from dataframe\n",
    "            dfBigDown = dfBig.sample(count_small, random_state=20)\n",
    "            dfResult = pd.concat([dfBigDown, dfSmall])\n",
    "            del dfBigDown\n",
    "\n",
    "        elif method == \"upsampling\": # from dataframe\n",
    "            dfSmallUp = dfSmall.sample(count_big, replace=True, random_state=20)\n",
    "            dfResult = pd.concat([dfBig, dfSmallUp])\n",
    "            del dfSmallUp\n",
    "\n",
    "        elif method == \"downresampl\": # from scikitlearn\n",
    "            dfBigDown = resample(dfBig, n_samples=count_small, random_state=20)\n",
    "            dfResult = pd.concat([dfBigDown, dfSmall])\n",
    "            del dfBigDown\n",
    "\n",
    "        elif method == \"upresampl\": # from scikitlearn\n",
    "            dfSmallUp = resample(dfSmall, replace=True, n_samples=count_big, random_state=20)\n",
    "            dfResult = pd.concat([dfBig, dfSmallUp])\n",
    "            del dfSmallUp\n",
    "            \n",
    "        dfResult.to_csv('result.csv',sep='\\t', index=False)\n",
    "        dfResult=pd.read_csv('result.csv', sep='\\t')\n",
    "        del dfBig, dfSmall\n",
    "\n",
    "    print(\"Apres\",method,\":\")\n",
    "    print(dfResult[column].value_counts())\n",
    "    \n",
    "    return dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "ZbyD7WGMMsS0",
    "outputId": "7b177ee0-35f1-4f31-d56d-8a4e292c70f9"
   },
   "outputs": [],
   "source": [
    "methodResampl = \"noresampling\" # noresampling downsampling upsampling downresampl upresampl\n",
    "methodes=[\"noresampling\", \"downsampling\", \"upsampling\", \"downresampl\", \"upresampl\"]\n",
    "dfResample = []\n",
    "\n",
    "for i in range(len(methodes)):\n",
    "    dfResample.append(resampleDf(dfNext, yColumnName, methodes[i]))\n",
    "    print(\"dfResample\",i,\"taille:\",dfResample[i].shape,\"\\n\")\n",
    "    print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4ot_VAMMsS4"
   },
   "source": [
    "### Evaluation des changements suite aux resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zdT6trbwMsS5",
    "outputId": "b928fcb1-a1fa-493d-8562-b2815c0f9fc3"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(len(methodes)):\n",
    "    print(methodes[i])\n",
    "    scores.append(do_classifier(dfResample[i], yColumnName, dfResample[i][XColumnName].copy(), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "0ViCmS7ZMsS9",
    "outputId": "bf87032e-88ac-4ac2-a4eb-52aeeaa73d24"
   },
   "outputs": [],
   "source": [
    "bestmean = 0\n",
    "index = 0\n",
    "for i in range(len(scores)):\n",
    "    if scores[i] >= bestmean:\n",
    "        methodResampl = methodes[i]\n",
    "        bestmean = scores[i]\n",
    "        index = i\n",
    "\n",
    "dfFinal = dfResample[index].copy()\n",
    "\n",
    "del dfNext, dfResample\n",
    "\n",
    "print(\"Apres Resample:\")\n",
    "display(dfFinal.head())\n",
    "print(\"dfFinal taille:\",dfFinal.shape,'\\n')\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftgunhihMsTA"
   },
   "source": [
    "## Recherche des meilleurs paramètres des classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7OMYonzMsTB"
   },
   "outputs": [],
   "source": [
    "def log_results(fileName, stop, lemm, addExtra, reSample, clf, param, score, t):\n",
    "    fichier = open(\"log.txt\", \"a\")\n",
    "    fichier.write(\"\\nJeu de données: %s\\n\" % (fileName))\n",
    "    if stop: s=\"True\"\n",
    "    else: s=\"False\"\n",
    "    fichier.write(\"Stop words: %s\\n\" % (s))\n",
    "    if lemm: l=\"True\"\n",
    "    else: l=\"False\"\n",
    "    fichier.write(\"Lemmatisation: %s\\n\" % (l))\n",
    "    fichier.write(\"Ajout d'extras: %s\\n\" % (addExtra))\n",
    "    fichier.write(\"Méthode resample: %s\\n\" % (reSample))\n",
    "    fichier.write(\"Classifieur: %s\\n\" % (clf))\n",
    "    fichier.write(\"Paramètres: %s\\n\" % (param))\n",
    "    fichier.write(\"Score: %.3f%%\\n\" % (score * 100.0))\n",
    "    fichier.write(\"Réalisé en %.1fs\\n\" % (t))\n",
    "    fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JpS5QJbJMsTF"
   },
   "outputs": [],
   "source": [
    "def do_gridsearch(name, estimClf, gridParam, X, y):\n",
    "\n",
    "    print(name,\": wait...\")\n",
    "    t0 = time()\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    gd_sr = GridSearchCV(estimator=estimClf,  \n",
    "                        param_grid=gridParam,\n",
    "                        scoring=scoring,\n",
    "                        cv=5,\n",
    "                        #n_jobs=-1,\n",
    "                        iid=True,\n",
    "                        return_train_score=True)\n",
    "\n",
    "    gd_sr.fit(X, y)\n",
    "\n",
    "    log_results(dataFile, StopWords, Lemmatiz, includeExtra, methodResampl,\n",
    "                  name, gd_sr.best_params_, gd_sr.best_score_,  time() - t0)\n",
    "    \n",
    "    print (\"Meilleurs paramètres: %s\" % (gd_sr.best_params_))\n",
    "    print (\"Meilleur score: %.3f%%\" % (gd_sr.best_score_ * 100.0))\n",
    "    print (\"Réalisé en %.1fs\\n\" % (time() - t0))\n",
    "    print (\"Meilleur estimateur\",gd_sr.best_estimator_,'\\n')\n",
    "    \n",
    "    gc.collect()\n",
    "    print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")    \n",
    "    \n",
    "    return gd_sr.best_params_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkAHKTlyMsTK"
   },
   "outputs": [],
   "source": [
    "jobsTodo= [\n",
    "    {\n",
    "        'clf' : 'GaussianNB',\n",
    "        'clfAbrev' : 'GNB',\n",
    "        'estimClf' : GaussianNB(),\n",
    "        'grid_param' : {}\n",
    "    },\n",
    "    {\n",
    "        'clf' : 'MultinomialNB',\n",
    "        'clfAbrev' : 'MNB',\n",
    "        'estimClf' : MultinomialNB(),\n",
    "        'grid_param' : {}\n",
    "    },\n",
    "    {\n",
    "        'clf' : 'LinearSVC',\n",
    "        'clfAbrev' : 'LSVC',\n",
    "        'estimClf' : LinearSVC(),\n",
    "        'grid_param' : {\n",
    "            'C': [0.01, 0.1, 0.4, 0.5, 0.6, 1, 9, 10, 11, 100],\n",
    "            'max_iter': [1000]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'clf' : 'LogisticRegression',\n",
    "        'clfAbrev' : 'LR',\n",
    "        'estimClf' : LogisticRegression(),\n",
    "        'grid_param' : {\n",
    "            'C' : [2,3,4,5,6,7,8],\n",
    "            'max_iter': [500, 1000]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'clf' : 'DecisionTreeClassifier',\n",
    "        'clfAbrev' : 'DTC',\n",
    "        'estimClf' : DecisionTreeClassifier(),\n",
    "        'grid_param' : {  \n",
    "            'max_depth': [7,8,9,10,11,12],\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'min_samples_leaf': [2,3,4,5,6,7,8]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'clf' : 'RandomForestClassifier',\n",
    "        'clfAbrev' : 'RFC',\n",
    "        'estimClf' : RandomForestClassifier(),\n",
    "        'grid_param' : {\n",
    "            'criterion': ['entropy', 'gini'],\n",
    "            'max_depth': [6, 9, 12], \n",
    "            'max_features': ['log2', 'sqrt','auto'], \n",
    "            'min_samples_leaf': [1, 5, 8],\n",
    "            'min_samples_split': [2, 3, 5],\n",
    "            'n_estimators': [6, 9, 12]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'clf' : 'SGDClassifier',\n",
    "        'clfAbrev' : 'SGDC',\n",
    "        'estimClf' : SGDClassifier(),\n",
    "        'grid_param' : {\n",
    "             'loss': ['log','hinge'],\n",
    "             'penalty': ['l1','l2']\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "ApN4AmtKMsTO",
    "outputId": "8d85dfbb-6544-4496-a61b-2b099dcfe881"
   },
   "outputs": [],
   "source": [
    "print(\"Preparation aux classifieurs...\")\n",
    "\n",
    "vectorizerT = TfidfVectorizer(min_df=2)\n",
    "vectorT = vectorizerT.fit_transform(dfFinal[XColumnName].copy())\n",
    "\n",
    "X=vectorT.toarray()\n",
    "y=dfFinal[yColumnName].copy()\n",
    "\n",
    "validation_size=0.25\n",
    "testsize= 1-validation_size\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=20,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "gc.collect()\n",
    "print(\"freememory=%2.3f Go\" %(psutil.virtual_memory().free/(1024 * 1024 * 1024)),\"\\n\")\n",
    "\n",
    "models = []\n",
    "for j in jobsTodo:\n",
    "    params = do_gridsearch(j['clf'], j['estimClf'], j['grid_param'], X_train, y_train)\n",
    "    models.append((j['clf'], j['clfAbrev'], j['estimClf'], params))\n",
    "    \n",
    "del vectorT, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1L1iWchiMsTS"
   },
   "source": [
    "## Recherche du meilleur classifieur paramétré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "vQAnLpjOMsTT",
    "outputId": "fad6768f-81d8-42f8-e944-c9c3efff9146"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "abrevs = []\n",
    "scores = []\n",
    "scoring = 'accuracy'\n",
    "print(\"wait...\\n\")\n",
    "for name,abrev,model,param in models:\n",
    "    model.set_params(**param)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=3)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    abrevs.append(abrev)\n",
    "    scores.append((name,model,param,cv_results.mean()))\n",
    "    msg = \"%s: %.3f%% (%.3f)\" % (name, cv_results.mean()*100, cv_results.std())\n",
    "    print(msg)\n",
    "gc.collect()\n",
    "print(\"\\nfreememory=%2.3f Go\" % (psutil.virtual_memory().free/(1024 * 1024 * 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "CVQ5l2x8MsTb",
    "outputId": "bd5c76cc-c08f-47be-d96e-50abb03ba3a4"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des classifieurs')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(abrevs)\n",
    "\n",
    "clfName = \"\"\n",
    "bestParam = \"\"\n",
    "bestmean = 0\n",
    "for name,model,param,mean in scores:\n",
    "    if mean > bestmean:\n",
    "        clfName = name\n",
    "        clfMethod = model\n",
    "        bestParam = param\n",
    "        bestmean = mean\n",
    "\n",
    "msg = \"Meilleur résultat: %s(%s) score:%.3f%%\" %(clfName, bestParam, bestmean*100)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyQ3Y-ViMsTk"
   },
   "source": [
    "## Evaluation finale avec l'ensemble des meilleurs choix retenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RB-WWwfVMsTm"
   },
   "outputs": [],
   "source": [
    "def perform_final():\n",
    "    t0 = time()\n",
    "    dfOrigin=pd.read_csv(dataFile, sep='\\t')\n",
    "\n",
    "    # ! necessaire pour mixture, a mettre en commentaire pour truefalse !\n",
    "    #dfOrigin.loc[dfOrigin[yColumnName] == -1, yColumnName] = 1\n",
    "\n",
    "    dfAjout = addExtras(dfOrigin, XColumnName, includeExtra, StopWords, Lemmatiz)\n",
    "    claimsMerge = merge_tokens(dfAjout.copy())\n",
    "    dfNext = NextDf(dfOrigin)\n",
    "    finalColumn = pd.DataFrame(claimsMerge)\n",
    "    finalColumn.columns = [XColumnName]\n",
    "    dfNext.update(finalColumn)\n",
    "    dfFinal = resampleDf(dfNext, yColumnName, methodResampl)\n",
    "    vectorizerT = TfidfVectorizer(min_df=2)\n",
    "    vectorT = vectorizerT.fit_transform(dfFinal[XColumnName].copy())\n",
    "    X=vectorT.toarray()\n",
    "    y=dfFinal[yColumnName].copy()\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=3)\n",
    "    clfMethod.set_params(**bestParam)\n",
    "    scoring = 'accuracy'\n",
    "    cv_results = cross_val_predict(clfMethod, X, y, cv=kfold)\n",
    "    log_results(dataFile, StopWords, Lemmatiz, includeExtra, methodResampl,\n",
    "                  clfName, bestParam, cv_results.mean(),  time() - t0)\n",
    "\n",
    "    accuracy = accuracy_score(y, cv_results)\n",
    "    precision,recall,fscore,support=score(y,cv_results,average='macro')\n",
    "\n",
    "    print(\"Accuracy: %.3f%%\" % (accuracy * 100.0))\n",
    "    print(\"F1-score moyen: %.3f%%\\n\" % (fscore * 100.0))\n",
    "    print ('Matrice de confusion:\\n', confusion_matrix(y, cv_results),'\\n')\n",
    "    print (classification_report(y, cv_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "ZpDx1TBnMsTq",
    "outputId": "d9935a67-6f36-4786-a081-112944c005dc"
   },
   "outputs": [],
   "source": [
    "print(\"dataFile= '%s'\" % (dataFile)) # data-truefalse-1.csv data-truefalse-2.csv data-truefalse-3.csv data-truefalse.csv\n",
    "print(\"XColumnName= '%s'\" % (XColumnName))\n",
    "print(\"yColumnName= '%s'\" % (yColumnName))\n",
    "print(\"StopWords=\",StopWords) # False True\n",
    "print(\"Lemmatiz=\",Lemmatiz)  # False True\n",
    "print(\"includeExtra= '%s'\" % (includeExtra)) # addnone addauthor addall\n",
    "print(\"methodResampl= '%s'\" % (methodResampl)) # noresampling downsampling upsampling downresampl upresampl\n",
    "print(\"clfName= '%s'\" % (clfName))\n",
    "print(\"clfMethod= \",clfMethod)\n",
    "print(\"bestParam= \",bestParam,\"\\n\")\n",
    "perform_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRA_rUAjMsTw"
   },
   "source": [
    "### Save des datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mjut-fAuMsTz",
    "outputId": "7b5144f2-df2b-41ad-8a6d-8c459637e573"
   },
   "outputs": [],
   "source": [
    "dfFinal.to_csv('result.csv',sep='\\t', index=False)\n",
    "print(\"Save to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_1Ur5e2MsT4"
   },
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "As8ZsxoYMsT5",
    "outputId": "ca6da6b2-6d4b-4c19-ea74-e52360d9a9f7"
   },
   "outputs": [],
   "source": [
    "assert False, \"breakpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84frrPh6MsT-"
   },
   "source": [
    "#### Sauvegarde des resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEmwmZdA6DWH"
   },
   "outputs": [],
   "source": [
    "dataFile= 'data-truefalse.csv'\n",
    "XColumnName= 'claimReview_claimReviewed'\n",
    "yColumnName= 'true_false_mixture'\n",
    "StopWords= False\n",
    "Lemmatiz= False\n",
    "includeExtra= 'addauthor'\n",
    "methodResampl= 'upresampl'\n",
    "clfName= 'LogisticRegression'\n",
    "clfMethod= LogisticRegression()\n",
    "bestParam= {'C': 8, 'max_iter': 500}\n",
    "perform_final() # pour relancer\n",
    "#Score= 84.014% (0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Q2rePxCqNken",
    "outputId": "e3f92013-99ff-4ae9-d047-ac4c29de90ae"
   },
   "outputs": [],
   "source": [
    "dataFile= 'data-mixture.csv'\n",
    "XColumnName= 'claimReview_claimReviewed'\n",
    "yColumnName= 'true_false_mixture'\n",
    "StopWords= False\n",
    "Lemmatiz= False\n",
    "includeExtra= 'addauthor'\n",
    "methodResampl= 'upresampl'\n",
    "clfName= 'LogisticRegression'\n",
    "clfMethod= LogisticRegression()\n",
    "bestParam=  {'C': 4, 'max_iter': 500}\n",
    "perform_final() # pour relancer\n",
    "#Score= 77.407% (0.002)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Projet-scenario-rapport.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
